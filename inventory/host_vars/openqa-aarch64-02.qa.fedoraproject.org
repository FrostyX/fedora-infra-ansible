---
freezes: false
# eth0 is on the .arm. network. eth1 is on the .qa. network
ansible_ifcfg_infra_net_devices: ['eth0', 'eth1']
gw: 10.5.131.254
dns: 10.5.126.21
eth1_ip: 10.5.131.26
eth1_nm: 255.255.255.0
datacenter: phx2
fas_client_groups: sysadmin-qa,sysadmin-main,sysadmin-noc,fi-apprentice,sysadmin-veteran
nrpe_procs_warn: 250
nrpe_procs_crit: 300

sudoers: "{{ private }}/files/sudo/qavirt-sudoers"

# we seem to have an eth2 plugged in that isn't configured here,
# which breaks "copy ifcfg files - non virthost" role
ansible_ifcfg_allowlist: ['eth0', 'eth1']
# we just want the eth1 (qa network) interface active
ansible_ifcfg_disabled: ['eth0']

# this is a powerful machine, can handle more openQA workers
openqa_workers: 8
# firewall ports for server->worker websockets connections
# this port is 'QEMUPORT plus 1'
# QEMUPORT is:
# $ENV{QEMUPORT} = ($options{instance}) * 10 + 20002;
# so for worker 1 it's 20012, for worker 2 it's 20022, etc etc
tcp_ports: ['20013', '20023', '20033', '20043', '20053', '20063', '20073', '20083']

# has an HW RNG, so let's have rngd
openqa_rngd: True

# FIXME this box is suffering from a mysterious bug that prevents VMs
# working properly:
# https://pagure.io/fedora-infrastructure/issue/8750
# this means all openQA tests run on it fail. We cannot currently work
# out why this is happening, so until we can, we will give it a special
# worker class that prevents it picking up regular jobs, but allows us
# to manually target it with jobs for debugging
openqa_worker_class: aarch64-02-broken
